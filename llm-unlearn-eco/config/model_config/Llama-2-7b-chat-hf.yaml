attack_module: model.embed_tokens
attn_implementation: flash_attention_2
embedding_dim: 4096
formatting_tokens:
  answer_prefix: ''
  answer_suffix: ''
  prompt_prefix: '[INST] '
  prompt_suffix: ' [/INST]'
hf_name: meta-llama/Llama-2-7b-chat-hf
load_in_4bit: false
load_in_8bit: false
model_name: /data2/models/Llama-2-7b-chat-hf
tokenizer_name: /data2/models/Llama-2-7b-chat-hf
